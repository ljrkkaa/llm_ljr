
linear attention
https://zhuanlan.zhihu.com/p/157490738#  归一化的行列写反了

kv cache
https://blog.csdn.net/taoqick/article/details/137476233

mask机制
https://ifwind.github.io/2021/08/17/Transformer%E7%9B%B8%E5%85%B3%E2%80%94%E2%80%94%EF%BC%887%EF%BC%89Mask%E6%9C%BA%E5%88%B6/#unilm%E4%B8%AD%E7%9A%84mask


