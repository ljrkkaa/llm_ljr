{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145bd49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0000,  1.0000,  1.0000,  0.9999],\n",
      "        [ 1.0000, -1.0000, -1.0000, -0.9999]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor([ 0.0000e+00,  0.0000e+00, -2.9802e-08, -2.9802e-08],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([1.0000, 1.0000, 1.0000, 0.9999], grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 一般用于batch下一个维度\n",
    "input = torch.randn(2,4)\n",
    "m = nn.BatchNorm1d(4)\n",
    "output = m(input)\n",
    "print(output)   \n",
    "print(output.mean(0))  # Mean across the batch dimension\n",
    "print(output.std(dim=0, unbiased=False))   # Standard deviation across the batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958808a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.9804, -0.2279,  1.3264],\n",
      "          [-0.1175,  0.7658,  1.6648]],\n",
      "\n",
      "         [[-0.0873, -0.8197, -0.2554],\n",
      "          [-0.5422,  2.2112, -0.1473]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0093, -0.9595, -0.4740],\n",
      "          [-0.8451, -0.1211, -0.0409]],\n",
      "\n",
      "         [[-0.2429, -0.2483,  0.3325],\n",
      "          [ 1.2085,  0.5927, -2.0018]]]], grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor([-1.9804, -0.2279,  1.3264, -0.1175,  0.7658,  1.6648,  1.0093, -0.9595,\n",
      "        -0.4740, -0.8451, -0.1211, -0.0409], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor(-2.4835e-08, grad_fn=<MeanBackward1>)\n",
      "tensor(1.0000, grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(2,2,2,3)    # [N, C, H, W] \n",
    "m = nn.BatchNorm2d(2)\n",
    "output = m(input)\n",
    "print(output)\n",
    "\n",
    "first_channel = output[:, 0, :, :].reshape(-1)\n",
    "print(first_channel)  # First channel of the output\n",
    "print(first_channel.mean(0))  # Mean across the batch dimension\n",
    "print(first_channel.std(dim=0, unbiased=False))  # Standard deviation across the batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f323c806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.2783e-08, grad_fn=<MeanBackward1>)\n",
      "tensor(1.0000, grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 均值和标准差是在最后 D 个维度上计算的\n",
    "batch, sentence_length, embedding_dim = 20, 5, 10\n",
    "embedding = torch.randn(batch, sentence_length, embedding_dim)\n",
    "layer_norm = nn.LayerNorm(embedding_dim)\n",
    "# Activate module\n",
    "output = layer_norm(embedding)\n",
    "\n",
    "print(output[0,0,:].mean(dim=0))\n",
    "print(output[0,0,:].std(dim=0, unbiased=False))  # Standard deviation across the embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8960fa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.1526e-09, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0000, grad_fn=<StdBackward0>)\n",
      "tensor([ 7.1526e-09, -6.6757e-09, -1.3828e-08,  1.9073e-09,  4.7684e-09,\n",
      "         1.9073e-09, -5.7220e-09,  1.0490e-08,  0.0000e+00, -6.6757e-09,\n",
      "        -1.1444e-08,  1.3351e-08, -4.7684e-09,  1.9073e-09,  7.0930e-09,\n",
      "        -5.7220e-09, -3.8147e-09, -1.9073e-09, -6.9141e-09,  1.7166e-08],\n",
      "       grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "N, C, H, W = 20, 5, 10, 10\n",
    "input = torch.randn(N, C, H, W)\n",
    "# Normalize over the last three dimensions (i.e. the channel and spatial dimensions)\n",
    "# as shown in the image below\n",
    "layer_norm = nn.LayerNorm([C, H, W])\n",
    "output = layer_norm(input)\n",
    "\n",
    "print(output[0,:].mean())\n",
    "print(output[0,:].std(unbiased=False))\n",
    "\n",
    "print(output.mean(dim=(1, 2, 3)))  # Mean across the batch and spatial dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe00289",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'RMSNorm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rms_norm \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRMSNorm\u001b[49m([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      3\u001b[0m rms_norm(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'RMSNorm'"
     ]
    }
   ],
   "source": [
    "# torch2.7才有\n",
    "rms_norm = nn.RMSNorm([2, 3])\n",
    "input = torch.randn(2, 2, 3)\n",
    "rms_norm(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98eb01a",
   "metadata": {},
   "source": [
    "layernorm VS RMSnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ad2e800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.1921e-08, grad_fn=<MeanBackward1>)\n",
      "tensor(1.0000, grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bs, seq_len, embedding_dim = 20, 5, 10\n",
    "x = torch.randn(bs, seq_len, embedding_dim)\n",
    "layer_norm = nn.LayerNorm(embedding_dim)\n",
    "output = layer_norm(x)\n",
    "print(output[2, 1, :].mean(dim=0))\n",
    "print(output[0, 3, :].std(dim=0, unbiased=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b0634cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "616e6e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3787,  1.7914,  1.4959,  0.8239, -0.7749,  0.8249, -0.8182,  0.2586,\n",
      "        -1.4281, -1.2396])\n",
      "tensor([-1.1814,  1.5350,  1.2818,  0.7059, -0.6640,  0.7068, -0.7011,  0.2216,\n",
      "        -1.2237, -1.0622], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "rms_norm = RMSNorm(embedding_dim)\n",
    "x_rms = rms_norm(x)\n",
    "print(x[0, 0, :])\n",
    "print(x_rms[0, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "463595ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1814,  1.5350,  1.2818,  0.7059, -0.6640,  0.7068, -0.7011,  0.2216,\n",
       "        -1.2237, -1.0622])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, :] / torch.sqrt(torch.sum(x[0, 0, :].pow(2)) / embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9707cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1623, grad_fn=<LinalgVectorNormBackward0>)\n",
      "3.1622776601683795\n"
     ]
    }
   ],
   "source": [
    "# 根号n 根号10 = 3.16\n",
    "print(torch.norm(x_rms[0, 0, :]))\n",
    "import numpy as np\n",
    "print(np.sqrt(embedding_dim))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
