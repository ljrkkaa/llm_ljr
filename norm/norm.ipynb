{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "145bd49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0000,  0.9947, -1.0000,  1.0000],\n",
      "        [ 1.0000, -0.9947,  1.0000, -1.0000]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor([0.0000e+00, 2.3842e-07, 0.0000e+00, 0.0000e+00],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "tensor([1.0000, 0.9947, 1.0000, 1.0000], grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 一般用于batch下一个维度\n",
    "input = torch.randn(2,4)\n",
    "m = nn.BatchNorm1d(4)\n",
    "output = m(input)\n",
    "print(output)   \n",
    "print(output.mean(0))  # Mean across the batch dimension\n",
    "print(output.std(dim=0, unbiased=False))   # Standard deviation across the batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "958808a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1321, -1.3829,  0.0633],\n",
      "          [-0.2338,  1.7586, -0.4787]],\n",
      "\n",
      "         [[-0.4129,  0.1674,  1.9476],\n",
      "          [-0.5788, -1.5462,  0.9578]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1817,  0.5309,  1.0532],\n",
      "          [-0.8182, -1.7818,  0.2397]],\n",
      "\n",
      "         [[-0.4996,  1.4713, -0.7869],\n",
      "          [-1.0685, -0.0793,  0.4281]]]], grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor([-0.1321, -1.3829,  0.0633, -0.2338,  1.7586, -0.4787,  1.1817,  0.5309,\n",
      "         1.0532, -0.8182, -1.7818,  0.2397], grad_fn=<UnsafeViewBackward0>)\n",
      "tensor(-4.9671e-09, grad_fn=<MeanBackward1>)\n",
      "tensor(1.0000, grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(2,2,2,3)    # [N, C, H, W] \n",
    "m = nn.BatchNorm2d(2)\n",
    "output = m(input)\n",
    "print(output)\n",
    "\n",
    "first_channel = output[:, 0, :, :].reshape(-1)\n",
    "print(first_channel)  # First channel of the output\n",
    "print(first_channel.mean(0))  # Mean across the batch dimension\n",
    "print(first_channel.std(dim=0, unbiased=False))  # Standard deviation across the batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f323c806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.5763e-08, grad_fn=<MeanBackward1>)\n",
      "tensor(1.0000, grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 均值和标准差是在最后 D 个维度上计算的\n",
    "batch, sentence_length, embedding_dim = 20, 5, 10\n",
    "embedding = torch.randn(batch, sentence_length, embedding_dim)\n",
    "layer_norm = nn.LayerNorm(embedding_dim)\n",
    "# Activate module\n",
    "output = layer_norm(embedding)\n",
    "\n",
    "print(output[0,0,:].mean(dim=0))\n",
    "print(output[0,0,:].std(dim=0, unbiased=False))  # Standard deviation across the embedding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8960fa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-9.5367e-10, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0000, grad_fn=<StdBackward0>)\n",
      "tensor([-9.5367e-10,  1.0490e-08, -9.5367e-10, -1.3351e-08, -1.9073e-09,\n",
      "         1.9073e-09,  9.5367e-09, -9.5367e-09, -2.8610e-09,  2.8610e-09,\n",
      "         5.7220e-09,  8.5831e-09, -1.9073e-09, -9.5367e-09,  3.8147e-09,\n",
      "         1.1444e-08,  1.2398e-08, -4.7684e-09,  0.0000e+00, -1.9073e-09],\n",
      "       grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "N, C, H, W = 20, 5, 10, 10\n",
    "input = torch.randn(N, C, H, W)\n",
    "# Normalize over the last three dimensions (i.e. the channel and spatial dimensions)\n",
    "# as shown in the image below\n",
    "layer_norm = nn.LayerNorm([C, H, W])\n",
    "output = layer_norm(input)\n",
    "\n",
    "print(output[0,:].mean())\n",
    "print(output[0,:].std(unbiased=False))\n",
    "\n",
    "print(output.mean(dim=(1, 2, 3)))  # Mean across the batch and spatial dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fe00289",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'RMSNorm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# torch2.7才有\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m rms_norm \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRMSNorm\u001b[49m([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      4\u001b[0m rms_norm(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'RMSNorm'"
     ]
    }
   ],
   "source": [
    "# torch2.7才有\n",
    "rms_norm = nn.RMSNorm([2, 3])\n",
    "input = torch.randn(2, 2, 3)\n",
    "rms_norm(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98eb01a",
   "metadata": {},
   "source": [
    "layernorm VS RMSnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ad2e800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.9605e-09, grad_fn=<MeanBackward1>)\n",
      "tensor(1.0000, grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bs, seq_len, embedding_dim = 20, 5, 10\n",
    "x = torch.randn(bs, seq_len, embedding_dim)\n",
    "layer_norm = nn.LayerNorm(embedding_dim)\n",
    "output = layer_norm(x)\n",
    "print(output[2, 1, :].mean(dim=0))\n",
    "print(output[0, 3, :].std(dim=0, unbiased=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b0634cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(torch.nn.Module):\n",
    "    def __init__(self, dim: int, eps: float = 1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(dim))\n",
    "\n",
    "    def _norm(self, x):\n",
    "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self._norm(x.float()).type_as(x)\n",
    "        return output * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "616e6e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 5, 1])\n",
      "tensor([ 0.7677, -0.5252, -0.8281, -0.1732,  0.3264,  0.3328,  0.9180,  0.7997,\n",
      "         2.9066, -0.8317])\n",
      "tensor([ 0.6889, -0.4713, -0.7430, -0.1554,  0.2928,  0.2986,  0.8237,  0.7176,\n",
      "         2.6080, -0.7463], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "rms_norm = RMSNorm(embedding_dim)\n",
    "x_rms = rms_norm(x)\n",
    "print(x.pow(2).mean(-1, keepdim=True).shape)\n",
    "print(x[0, 0, :])\n",
    "print(x_rms[0, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463595ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1814,  1.5350,  1.2818,  0.7059, -0.6640,  0.7068, -0.7011,  0.2216,\n",
       "        -1.2237, -1.0622])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, :] / torch.sqrt(torch.sum(x[0, 0, :].pow(2)) / embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9707cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.1623, grad_fn=<LinalgVectorNormBackward0>)\n",
      "3.1622776601683795\n"
     ]
    }
   ],
   "source": [
    "# 根号n 根号10 = 3.16\n",
    "print(torch.norm(x_rms[0, 0, :]))\n",
    "import numpy as np\n",
    "print(np.sqrt(embedding_dim))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qwen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
