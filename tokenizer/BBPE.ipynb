{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb1077a6",
   "metadata": {},
   "source": [
    "Unicode 是字符集，为每个字符分配唯一的代码点。\n",
    "UTF-8 是一种基于 Unicode 的字符编码方式，用于在计算机中存储和传输字符。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fe357e",
   "metadata": {},
   "source": [
    "BPE理论上还是会出现OOV的，当词汇表的大小受限时，一些较少频繁出现的子词和没有在训练过程中见过的子词，就会无法进入词汇表出现OOV，而Byte-level BPE(BBPE)理论上是不会出现这个情况的。\n",
    "\n",
    "Byte-level BPE(BBPE)和Byte-Pair Encoding (BPE)区别就是BPE是最小词汇是字符级别，而BBPE是字节级别的，通过UTF-8的编码方式这一个字节的256的范围，理论上可以表示这个世界上的所有字符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "49c4635c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_vocab: [b'\\x00', b'\\x01', b'\\x02', b'\\x03', b'\\x04', b'\\x05', b'\\x06', b'\\x07', b'\\x08', b'\\t', b'\\n', b'\\x0b', b'\\x0c', b'\\r', b'\\x0e', b'\\x0f', b'\\x10', b'\\x11', b'\\x12', b'\\x13', b'\\x14', b'\\x15', b'\\x16', b'\\x17', b'\\x18', b'\\x19', b'\\x1a', b'\\x1b', b'\\x1c', b'\\x1d', b'\\x1e', b'\\x1f', b' ', b'!', b'\"', b'#', b'$', b'%', b'&', b\"'\", b'(', b')', b'*', b'+', b',', b'-', b'.', b'/', b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', b'9', b':', b';', b'<', b'=', b'>', b'?', b'@', b'A', b'B', b'C', b'D', b'E', b'F', b'G', b'H', b'I', b'J', b'K', b'L', b'M', b'N', b'O', b'P', b'Q', b'R', b'S', b'T', b'U', b'V', b'W', b'X', b'Y', b'Z', b'[', b'\\\\', b']', b'^', b'_', b'`', b'a', b'b', b'c', b'd', b'e', b'f', b'g', b'h', b'i', b'j', b'k', b'l', b'm', b'n', b'o', b'p', b'q', b'r', b's', b't', b'u', b'v', b'w', b'x', b'y', b'z', b'{', b'|', b'}', b'~', b'\\x7f', b'\\x80', b'\\x81', b'\\x82', b'\\x83', b'\\x84', b'\\x85', b'\\x86', b'\\x87', b'\\x88', b'\\x89', b'\\x8a', b'\\x8b', b'\\x8c', b'\\x8d', b'\\x8e', b'\\x8f', b'\\x90', b'\\x91', b'\\x92', b'\\x93', b'\\x94', b'\\x95', b'\\x96', b'\\x97', b'\\x98', b'\\x99', b'\\x9a', b'\\x9b', b'\\x9c', b'\\x9d', b'\\x9e', b'\\x9f', b'\\xa0', b'\\xa1', b'\\xa2', b'\\xa3', b'\\xa4', b'\\xa5', b'\\xa6', b'\\xa7', b'\\xa8', b'\\xa9', b'\\xaa', b'\\xab', b'\\xac', b'\\xad', b'\\xae', b'\\xaf', b'\\xb0', b'\\xb1', b'\\xb2', b'\\xb3', b'\\xb4', b'\\xb5', b'\\xb6', b'\\xb7', b'\\xb8', b'\\xb9', b'\\xba', b'\\xbb', b'\\xbc', b'\\xbd', b'\\xbe', b'\\xbf', b'\\xc0', b'\\xc1', b'\\xc2', b'\\xc3', b'\\xc4', b'\\xc5', b'\\xc6', b'\\xc7', b'\\xc8', b'\\xc9', b'\\xca', b'\\xcb', b'\\xcc', b'\\xcd', b'\\xce', b'\\xcf', b'\\xd0', b'\\xd1', b'\\xd2', b'\\xd3', b'\\xd4', b'\\xd5', b'\\xd6', b'\\xd7', b'\\xd8', b'\\xd9', b'\\xda', b'\\xdb', b'\\xdc', b'\\xdd', b'\\xde', b'\\xdf', b'\\xe0', b'\\xe1', b'\\xe2', b'\\xe3', b'\\xe4', b'\\xe5', b'\\xe6', b'\\xe7', b'\\xe8', b'\\xe9', b'\\xea', b'\\xeb', b'\\xec', b'\\xed', b'\\xee', b'\\xef', b'\\xf0', b'\\xf1', b'\\xf2', b'\\xf3', b'\\xf4', b'\\xf5', b'\\xf6', b'\\xf7', b'\\xf8', b'\\xf9', b'\\xfa', b'\\xfb', b'\\xfc', b'\\xfd', b'\\xfe', b'\\xff']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "sentences = [\n",
    "    \"我\",\n",
    "    \"喜欢\",\n",
    "    \"吃\",\n",
    "    \"苹果\",\n",
    "    \"他\",\n",
    "    \"不\",\n",
    "    \"喜欢\",\n",
    "    \"吃\",\n",
    "    \"苹果派\",\n",
    "    \"I like to eat apples\",\n",
    "    \"She has a cute cat\",\n",
    "    \"you are very cute\",\n",
    "    \"give you a hug\",\n",
    "]\n",
    "# 构建初始词汇表，包含一个字节的256个表示\n",
    "initial_vocab = [bytes([byte]) for byte in range(256)]\n",
    "vocab = initial_vocab.copy()\n",
    "print(\"initial_vocab:\", initial_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "991f3896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats: defaultdict(<class 'int'>, {b'\\xe6\\x88\\x91': 1, b'\\xe5\\x96\\x9c\\xe6\\xac\\xa2': 2, b'\\xe5\\x90\\x83': 2, b'\\xe8\\x8b\\xb9\\xe6\\x9e\\x9c': 1, b'\\xe4\\xbb\\x96': 1, b'\\xe4\\xb8\\x8d': 1, b'\\xe8\\x8b\\xb9\\xe6\\x9e\\x9c\\xe6\\xb4\\xbe': 1, b'I': 1, b'like': 1, b'to': 1, b'eat': 1, b'apples': 1, b'She': 1, b'has': 1, b'a': 2, b'cute': 2, b'cat': 1, b'you': 2, b'are': 1, b'very': 1, b'give': 1, b'hug': 1})\n",
      "splits: {b'\\xe6\\x88\\x91': ['æ', '\\x88', '\\x91'], b'\\xe5\\x96\\x9c\\xe6\\xac\\xa2': ['å', '\\x96', '\\x9c', 'æ', '¬', '¢'], b'\\xe5\\x90\\x83': ['å', '\\x90', '\\x83'], b'\\xe8\\x8b\\xb9\\xe6\\x9e\\x9c': ['è', '\\x8b', '¹', 'æ', '\\x9e', '\\x9c'], b'\\xe4\\xbb\\x96': ['ä', '»', '\\x96'], b'\\xe4\\xb8\\x8d': ['ä', '¸', '\\x8d'], b'\\xe8\\x8b\\xb9\\xe6\\x9e\\x9c\\xe6\\xb4\\xbe': ['è', '\\x8b', '¹', 'æ', '\\x9e', '\\x9c', 'æ', '´', '¾'], b'I': ['I'], b'like': ['l', 'i', 'k', 'e'], b'to': ['t', 'o'], b'eat': ['e', 'a', 't'], b'apples': ['a', 'p', 'p', 'l', 'e', 's'], b'She': ['S', 'h', 'e'], b'has': ['h', 'a', 's'], b'a': ['a'], b'cute': ['c', 'u', 't', 'e'], b'cat': ['c', 'a', 't'], b'you': ['y', 'o', 'u'], b'are': ['a', 'r', 'e'], b'very': ['v', 'e', 'r', 'y'], b'give': ['g', 'i', 'v', 'e'], b'hug': ['h', 'u', 'g']}\n"
     ]
    }
   ],
   "source": [
    "# 构建频率统计\n",
    "def build_stats(sentences):\n",
    "    stats = defaultdict(int)\n",
    "    for sentence in sentences:\n",
    "        symbols = sentence.split()\n",
    "        for symbol in symbols:\n",
    "            stats[symbol.encode(\"utf-8\")] += 1\n",
    "    return stats\n",
    "stats = build_stats(sentences)\n",
    "\n",
    "splits = {word: [bytes([byte]).decode('latin1') for byte in word] for word in stats.keys()}\n",
    "\n",
    "print(\"stats:\", stats)\n",
    "print(\"splits:\", splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e2786a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('æ', '\\x88'): 1\n",
      "('\\x88', '\\x91'): 1\n",
      "('å', '\\x96'): 2\n",
      "('\\x96', '\\x9c'): 2\n",
      "('\\x9c', 'æ'): 3\n",
      "('æ', '¬'): 2\n",
      "('¬', '¢'): 2\n",
      "('å', '\\x90'): 2\n",
      "('\\x90', '\\x83'): 2\n",
      "('è', '\\x8b'): 2\n",
      "('\\x8b', '¹'): 2\n",
      "('¹', 'æ'): 2\n",
      "('æ', '\\x9e'): 2\n",
      "('\\x9e', '\\x9c'): 2\n",
      "('ä', '»'): 1\n",
      "('»', '\\x96'): 1\n",
      "('ä', '¸'): 1\n",
      "('¸', '\\x8d'): 1\n",
      "('æ', '´'): 1\n",
      "('´', '¾'): 1\n"
     ]
    }
   ],
   "source": [
    "def compute_pair_freqs(splits):\n",
    "    pair_freqs = defaultdict(int)\n",
    "    for word, freq in stats.items():\n",
    "        split = splits[word]\n",
    "        if len(split) == 1:\n",
    "            continue\n",
    "        for i in range(len(split) - 1):\n",
    "            pair = (split[i], split[i + 1])\n",
    "            pair_freqs[pair] += freq\n",
    "    return pair_freqs\n",
    "\n",
    "pair_freqs = compute_pair_freqs(splits)\n",
    "\n",
    "for i, key in enumerate(pair_freqs.keys()):\n",
    "    print(f\"{key}: {pair_freqs[key]}\")\n",
    "    if i >= 19:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ee78fdb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\x9c', 'æ') 3\n"
     ]
    }
   ],
   "source": [
    "best_pair = \"\"\n",
    "max_freq = None\n",
    "for pair, freq in pair_freqs.items():\n",
    "    if max_freq is None or max_freq < freq:\n",
    "        best_pair = pair\n",
    "        max_freq = freq\n",
    "\n",
    "print(best_pair, max_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d9b978c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splits: {b'\\xe6\\x88\\x91': ['æ', '\\x88', '\\x91'], b'\\xe5\\x96\\x9c\\xe6\\xac\\xa2': ['å', '\\x96', '\\x9c', 'æ', '¬', '¢'], b'\\xe5\\x90\\x83': ['å', '\\x90', '\\x83'], b'\\xe8\\x8b\\xb9\\xe6\\x9e\\x9c': ['è', '\\x8b', '¹', 'æ', '\\x9e', '\\x9c'], b'\\xe4\\xbb\\x96': ['ä', '»', '\\x96'], b'\\xe4\\xb8\\x8d': ['ä', '¸', '\\x8d'], b'\\xe8\\x8b\\xb9\\xe6\\x9e\\x9c\\xe6\\xb4\\xbe': ['è', '\\x8b', '¹', 'æ', '\\x9e', '\\x9c', 'æ', '´', '¾'], b'I': ['I'], b'like': ['l', 'i', 'k', 'e'], b'to': ['t', 'o'], b'eat': ['e', 'a', 't'], b'apples': ['a', 'p', 'p', 'l', 'e', 's'], b'She': ['S', 'h', 'e'], b'has': ['h', 'a', 's'], b'a': ['a'], b'cute': ['c', 'u', 't', 'e'], b'cat': ['c', 'a', 't'], b'you': ['y', 'o', 'u'], b'are': ['a', 'r', 'e'], b'very': ['v', 'e', 'r', 'y'], b'give': ['g', 'i', 'v', 'e'], b'hug': ['h', 'u', 'g']}\n"
     ]
    }
   ],
   "source": [
    "def merge_pair(pair, splits):\n",
    "    merged_byte = pair\n",
    "    for word in stats:\n",
    "        split = splits[word]\n",
    "        if len(split) == 1:\n",
    "            continue\n",
    "        i = 0\n",
    "        while i < len(split) - 1:\n",
    "            if split[i:i+2] == pair:  # 检查分割中是否有这对字节\n",
    "                split = split[:i] + [merged_byte] + split[i + 2 :]\n",
    "            else:\n",
    "                i += 1\n",
    "        splits[word] = split\n",
    "    return splits\n",
    "\n",
    "splits = merge_pair(best_pair, splits)\n",
    "print(\"splits:\", splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "514ab54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "merges: {('\\x9c', 'æ'): ('\\x9c', 'æ')}\n",
      "vocab: [b'\\x00', b'\\x01', b'\\x02', b'\\x03', b'\\x04', b'\\x05', b'\\x06', b'\\x07', b'\\x08', b'\\t', b'\\n', b'\\x0b', b'\\x0c', b'\\r', b'\\x0e', b'\\x0f', b'\\x10', b'\\x11', b'\\x12', b'\\x13', b'\\x14', b'\\x15', b'\\x16', b'\\x17', b'\\x18', b'\\x19', b'\\x1a', b'\\x1b', b'\\x1c', b'\\x1d', b'\\x1e', b'\\x1f', b' ', b'!', b'\"', b'#', b'$', b'%', b'&', b\"'\", b'(', b')', b'*', b'+', b',', b'-', b'.', b'/', b'0', b'1', b'2', b'3', b'4', b'5', b'6', b'7', b'8', b'9', b':', b';', b'<', b'=', b'>', b'?', b'@', b'A', b'B', b'C', b'D', b'E', b'F', b'G', b'H', b'I', b'J', b'K', b'L', b'M', b'N', b'O', b'P', b'Q', b'R', b'S', b'T', b'U', b'V', b'W', b'X', b'Y', b'Z', b'[', b'\\\\', b']', b'^', b'_', b'`', b'a', b'b', b'c', b'd', b'e', b'f', b'g', b'h', b'i', b'j', b'k', b'l', b'm', b'n', b'o', b'p', b'q', b'r', b's', b't', b'u', b'v', b'w', b'x', b'y', b'z', b'{', b'|', b'}', b'~', b'\\x7f', b'\\x80', b'\\x81', b'\\x82', b'\\x83', b'\\x84', b'\\x85', b'\\x86', b'\\x87', b'\\x88', b'\\x89', b'\\x8a', b'\\x8b', b'\\x8c', b'\\x8d', b'\\x8e', b'\\x8f', b'\\x90', b'\\x91', b'\\x92', b'\\x93', b'\\x94', b'\\x95', b'\\x96', b'\\x97', b'\\x98', b'\\x99', b'\\x9a', b'\\x9b', b'\\x9c', b'\\x9d', b'\\x9e', b'\\x9f', b'\\xa0', b'\\xa1', b'\\xa2', b'\\xa3', b'\\xa4', b'\\xa5', b'\\xa6', b'\\xa7', b'\\xa8', b'\\xa9', b'\\xaa', b'\\xab', b'\\xac', b'\\xad', b'\\xae', b'\\xaf', b'\\xb0', b'\\xb1', b'\\xb2', b'\\xb3', b'\\xb4', b'\\xb5', b'\\xb6', b'\\xb7', b'\\xb8', b'\\xb9', b'\\xba', b'\\xbb', b'\\xbc', b'\\xbd', b'\\xbe', b'\\xbf', b'\\xc0', b'\\xc1', b'\\xc2', b'\\xc3', b'\\xc4', b'\\xc5', b'\\xc6', b'\\xc7', b'\\xc8', b'\\xc9', b'\\xca', b'\\xcb', b'\\xcc', b'\\xcd', b'\\xce', b'\\xcf', b'\\xd0', b'\\xd1', b'\\xd2', b'\\xd3', b'\\xd4', b'\\xd5', b'\\xd6', b'\\xd7', b'\\xd8', b'\\xd9', b'\\xda', b'\\xdb', b'\\xdc', b'\\xdd', b'\\xde', b'\\xdf', b'\\xe0', b'\\xe1', b'\\xe2', b'\\xe3', b'\\xe4', b'\\xe5', b'\\xe6', b'\\xe7', b'\\xe8', b'\\xe9', b'\\xea', b'\\xeb', b'\\xec', b'\\xed', b'\\xee', b'\\xef', b'\\xf0', b'\\xf1', b'\\xf2', b'\\xf3', b'\\xf4', b'\\xf5', b'\\xf6', b'\\xf7', b'\\xf8', b'\\xf9', b'\\xfa', b'\\xfb', b'\\xfc', b'\\xfd', b'\\xfe', b'\\xff', ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ'), ('\\x9c', 'æ')]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 500\n",
    "merges = {}\n",
    "print(len(vocab))\n",
    "\n",
    "while len(vocab) < vocab_size:\n",
    "    pair_freqs = compute_pair_freqs(splits)\n",
    "    best_pair = ()\n",
    "    max_freq = None\n",
    "    for pair, freq in pair_freqs.items():\n",
    "        if max_freq is None or max_freq < freq:\n",
    "            best_pair = pair\n",
    "            max_freq = freq\n",
    "    splits = merge_pair(best_pair, splits)\n",
    "    merged_byte = best_pair\n",
    "    merges[best_pair] = merged_byte\n",
    "    vocab.append(merged_byte)\n",
    "\n",
    "print(\"merges:\", merges)\n",
    "print(\"vocab:\", vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
